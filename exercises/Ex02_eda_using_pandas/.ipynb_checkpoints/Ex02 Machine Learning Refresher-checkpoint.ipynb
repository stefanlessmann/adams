{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python primer #2: supervised machine learning revisited\n",
    "\n",
    "Welcome to our second ADAMS exercise. Today, we revisit some standard practices in supervised machine learning.\n",
    "Similar content was part of the lecture [Business Analytics and Data Science](https://moodle.hu-berlin.de/course/view.php?id=90853)\n",
    ", which many of you will have attended. Let us see how Python supports supervised ML. \n",
    "\n",
    "Here is the outline of today. \n",
    "\n",
    "1. Scikit-learn and classification\n",
    "2. Cross-entropy and Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scikit-learn** will be the \"go-to\" library when it comes to machine learning. Make sure to have it installed if you \n",
    "use your own computer. Of course, it is part of the Anaconda distribution. Since the functionality of scikit-learn is \n",
    "massive, it is good practice to not import the whole library but the parts that you need. We illustrate this approach \n",
    "below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# scikit-learn (sklearn) is *the* standard package for machine learning in python. Commonly needed functions include:\n",
    "\n",
    "# Data split function\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "\n",
    "# Model tuning functions\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Model training functions\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Libraries to calculate various metrics\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic modelling (random forest)\n",
    "We will first load some standard Python libraries for data handling, most importantly Pandas, \n",
    "load a [Kaggle data set](https://www.kaggle.com/mhdzahier/travel-insurance?#travel%20insurance.csv)\n",
    "related to insurance claims, and then apply some standard Pandas functions to the resulting data frame\n",
    "for getting an overview of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Importing libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# This is were I store the data on my computer. You will have to change this.\n",
    "file_name: str = '../../data/travel insurance.csv'\n",
    "\n",
    "if os.path.exists(file_name):\n",
    "    data = pd.read_csv(file_name)\n",
    "else:\n",
    "    url: str = 'https://github.com/Kaggle/kaggle-api'\n",
    "    print('File {} not found. Check where on your hard disk you stored the data.'.format(file_name))\n",
    "    print('Even better, check out {} for examples how to load data directly from kaggle.'.format(url))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of the function: head\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agency</th>\n",
       "      <th>Agency Type</th>\n",
       "      <th>Distribution Channel</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Claim</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Net Sales</th>\n",
       "      <th>Commision (in value)</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBH</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Comprehensive Plan</td>\n",
       "      <td>No</td>\n",
       "      <td>186</td>\n",
       "      <td>MALAYSIA</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>9.57</td>\n",
       "      <td>F</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBH</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Comprehensive Plan</td>\n",
       "      <td>No</td>\n",
       "      <td>186</td>\n",
       "      <td>MALAYSIA</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>9.57</td>\n",
       "      <td>F</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CWT</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>Rental Vehicle Excess Insurance</td>\n",
       "      <td>No</td>\n",
       "      <td>65</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>-49.5</td>\n",
       "      <td>29.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CWT</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>Rental Vehicle Excess Insurance</td>\n",
       "      <td>No</td>\n",
       "      <td>60</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>-39.6</td>\n",
       "      <td>23.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Agency    Agency Type Distribution Channel                     Product Name  \\\n",
       "0    CBH  Travel Agency              Offline               Comprehensive Plan   \n",
       "1    CBH  Travel Agency              Offline               Comprehensive Plan   \n",
       "2    CWT  Travel Agency               Online  Rental Vehicle Excess Insurance   \n",
       "3    CWT  Travel Agency               Online  Rental Vehicle Excess Insurance   \n",
       "\n",
       "  Claim  Duration Destination  Net Sales  Commision (in value) Gender  Age  \n",
       "0    No       186    MALAYSIA      -29.0                  9.57      F   81  \n",
       "1    No       186    MALAYSIA      -29.0                  9.57      F   71  \n",
       "2    No        65   AUSTRALIA      -49.5                 29.70    NaN   32  \n",
       "3    No        60   AUSTRALIA      -39.6                 23.76    NaN   32  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of the function: describe\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>Net Sales</th>\n",
       "      <th>Commision (in value)</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>63326.000000</td>\n",
       "      <td>63326.000000</td>\n",
       "      <td>63326.000000</td>\n",
       "      <td>63326.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49.317074</td>\n",
       "      <td>40.702018</td>\n",
       "      <td>9.809992</td>\n",
       "      <td>39.969981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>101.791566</td>\n",
       "      <td>48.845637</td>\n",
       "      <td>19.804388</td>\n",
       "      <td>14.017010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-389.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>26.530000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>11.550000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4881.000000</td>\n",
       "      <td>810.000000</td>\n",
       "      <td>283.500000</td>\n",
       "      <td>118.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Duration     Net Sales  Commision (in value)           Age\n",
       "count  63326.000000  63326.000000          63326.000000  63326.000000\n",
       "mean      49.317074     40.702018              9.809992     39.969981\n",
       "std      101.791566     48.845637             19.804388     14.017010\n",
       "min       -2.000000   -389.000000              0.000000      0.000000\n",
       "25%        9.000000     18.000000              0.000000     35.000000\n",
       "50%       22.000000     26.530000              0.000000     36.000000\n",
       "75%       53.000000     48.000000             11.550000     43.000000\n",
       "max     4881.000000    810.000000            283.500000    118.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of df.dtypes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Agency                   object\n",
       "Agency Type              object\n",
       "Distribution Channel     object\n",
       "Product Name             object\n",
       "Claim                    object\n",
       "Duration                  int64\n",
       "Destination              object\n",
       "Net Sales               float64\n",
       "Commision (in value)    float64\n",
       "Gender                   object\n",
       "Age                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When dropping columns by name, don't forget to specify the axis. Drop defaults to axis=0, which is row-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data=data.drop(['Destination'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=63326, step=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas offers many convenience functions to solve common data science tasks.\n",
    "For example, drop rows (or columns) that contain missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data=data.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Agency', 'Agency Type', 'Distribution Channel', 'Product Name',\n",
       "       'Claim', 'Duration', 'Net Sales', 'Commision (in value)', 'Gender',\n",
       "       'Age'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X=data.drop(['Claim'], axis=1)\n",
    "y=data.Claim # or data[\"Claim\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03507327515231352"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=y.map({'Yes': 1, 'No': 0})\n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn's Random Forest can not process categorical data, unlike its R counterpart. \n",
    "Hence, we will need to use __one-hot encoding__ . We can use Pandas or Sklearn for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>Net Sales</th>\n",
       "      <th>Commision (in value)</th>\n",
       "      <th>Age</th>\n",
       "      <th>Agency_ADM</th>\n",
       "      <th>Agency_ART</th>\n",
       "      <th>Agency_C2B</th>\n",
       "      <th>Agency_CBH</th>\n",
       "      <th>Agency_CCR</th>\n",
       "      <th>Agency_CSR</th>\n",
       "      <th>...</th>\n",
       "      <th>Product Name_Silver Plan</th>\n",
       "      <th>Product Name_Single Trip Travel Protect Gold</th>\n",
       "      <th>Product Name_Single Trip Travel Protect Platinum</th>\n",
       "      <th>Product Name_Single Trip Travel Protect Silver</th>\n",
       "      <th>Product Name_Spouse or Parents Comprehensive Plan</th>\n",
       "      <th>Product Name_Travel Cruise Protect</th>\n",
       "      <th>Product Name_Travel Cruise Protect Family</th>\n",
       "      <th>Product Name_Value Plan</th>\n",
       "      <th>Gender_F</th>\n",
       "      <th>Gender_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>186</td>\n",
       "      <td>-29.00</td>\n",
       "      <td>9.57</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>-29.00</td>\n",
       "      <td>9.57</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>66</td>\n",
       "      <td>-121.00</td>\n",
       "      <td>42.35</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>-18.00</td>\n",
       "      <td>6.30</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>53</td>\n",
       "      <td>-130.00</td>\n",
       "      <td>49.40</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>-18.00</td>\n",
       "      <td>6.30</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12</td>\n",
       "      <td>46.15</td>\n",
       "      <td>11.54</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>17.55</td>\n",
       "      <td>4.39</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12</td>\n",
       "      <td>94.00</td>\n",
       "      <td>23.50</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>190</td>\n",
       "      <td>294.75</td>\n",
       "      <td>73.69</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Duration  Net Sales  Commision (in value)  Age  Agency_ADM  Agency_ART  \\\n",
       "0        186     -29.00                  9.57   81           0           0   \n",
       "1        186     -29.00                  9.57   71           0           0   \n",
       "5         66    -121.00                 42.35   44           0           0   \n",
       "11         1     -18.00                  6.30   47           0           0   \n",
       "12        53    -130.00                 49.40   48           0           0   \n",
       "18         3     -18.00                  6.30   47           0           0   \n",
       "21        12      46.15                 11.54   44           0           0   \n",
       "22         7      17.55                  4.39   25           0           0   \n",
       "23        12      94.00                 23.50   34           0           0   \n",
       "24       190     294.75                 73.69   26           0           0   \n",
       "\n",
       "    Agency_C2B  Agency_CBH  Agency_CCR  Agency_CSR  ...  \\\n",
       "0            0           1           0           0  ...   \n",
       "1            0           1           0           0  ...   \n",
       "5            0           0           0           0  ...   \n",
       "11           0           0           0           0  ...   \n",
       "12           0           0           0           0  ...   \n",
       "18           0           0           0           0  ...   \n",
       "21           1           0           0           0  ...   \n",
       "22           1           0           0           0  ...   \n",
       "23           1           0           0           0  ...   \n",
       "24           1           0           0           0  ...   \n",
       "\n",
       "    Product Name_Silver Plan  Product Name_Single Trip Travel Protect Gold  \\\n",
       "0                          0                                             0   \n",
       "1                          0                                             0   \n",
       "5                          0                                             0   \n",
       "11                         0                                             0   \n",
       "12                         0                                             0   \n",
       "18                         0                                             0   \n",
       "21                         0                                             0   \n",
       "22                         0                                             0   \n",
       "23                         0                                             0   \n",
       "24                         1                                             0   \n",
       "\n",
       "    Product Name_Single Trip Travel Protect Platinum  \\\n",
       "0                                                  0   \n",
       "1                                                  0   \n",
       "5                                                  0   \n",
       "11                                                 0   \n",
       "12                                                 0   \n",
       "18                                                 0   \n",
       "21                                                 0   \n",
       "22                                                 0   \n",
       "23                                                 0   \n",
       "24                                                 0   \n",
       "\n",
       "    Product Name_Single Trip Travel Protect Silver  \\\n",
       "0                                                0   \n",
       "1                                                0   \n",
       "5                                                0   \n",
       "11                                               0   \n",
       "12                                               0   \n",
       "18                                               0   \n",
       "21                                               0   \n",
       "22                                               0   \n",
       "23                                               0   \n",
       "24                                               0   \n",
       "\n",
       "    Product Name_Spouse or Parents Comprehensive Plan  \\\n",
       "0                                                   0   \n",
       "1                                                   0   \n",
       "5                                                   0   \n",
       "11                                                  0   \n",
       "12                                                  0   \n",
       "18                                                  0   \n",
       "21                                                  0   \n",
       "22                                                  0   \n",
       "23                                                  0   \n",
       "24                                                  0   \n",
       "\n",
       "    Product Name_Travel Cruise Protect  \\\n",
       "0                                    0   \n",
       "1                                    0   \n",
       "5                                    0   \n",
       "11                                   0   \n",
       "12                                   0   \n",
       "18                                   0   \n",
       "21                                   0   \n",
       "22                                   0   \n",
       "23                                   0   \n",
       "24                                   0   \n",
       "\n",
       "    Product Name_Travel Cruise Protect Family  Product Name_Value Plan  \\\n",
       "0                                           0                        0   \n",
       "1                                           0                        0   \n",
       "5                                           0                        1   \n",
       "11                                          0                        0   \n",
       "12                                          0                        0   \n",
       "18                                          0                        0   \n",
       "21                                          0                        0   \n",
       "22                                          0                        0   \n",
       "23                                          0                        0   \n",
       "24                                          0                        0   \n",
       "\n",
       "    Gender_F  Gender_M  \n",
       "0          1         0  \n",
       "1          1         0  \n",
       "5          1         0  \n",
       "11         0         1  \n",
       "12         1         0  \n",
       "18         0         1  \n",
       "21         1         0  \n",
       "22         1         0  \n",
       "23         0         1  \n",
       "24         0         1  \n",
       "\n",
       "[10 rows x 46 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= pd.get_dummies(X, prefix_sep=\"_\",columns=X.select_dtypes(include=[object]).columns)\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data in place, let' create a random forest classifier to predict y from X.\n",
    "Similar to R's {mlr}, we first create a model as an object and set its parameters and options. \n",
    "Think of this as a concrete specification of the abstract algorithm Random Forest. \n",
    "We then fit the model to the actual data using a method of the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=15, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/Fit a model\n",
    "fullmodel = RandomForestClassifier(n_estimators=10, # Forest with n trees\n",
    "                                   max_depth=15) # and very shallow\n",
    "fullmodel.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = fullmodel.predict(X)\n",
    "print(y_pred[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original output of predict_proba function...\n",
      "[[0.99756098 0.00243902]\n",
      " [0.99756098 0.00243902]\n",
      " [0.99836066 0.00163934]\n",
      " [1.         0.        ]\n",
      " [1.         0.        ]]\n",
      "... and what you typically need:\n",
      "[0.00243902 0.00243902 0.00163934 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Probabilities are returned for each class, unfortunately without the class names\n",
    "y_pred_prob = fullmodel.predict_proba(X)\n",
    "print('Original output of predict_proba function...')\n",
    "print(y_pred_prob[0:5])\n",
    "print('... and what you typically need:')\n",
    "y_pred_prob = y_pred_prob[:,1]\n",
    "print(y_pred_prob[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[17578     2]\n",
      " [  516   123]]\n",
      "Classification Accuracy:  0.9715681431472638\n",
      "Classification Error: \t 0.028431856852736193\n",
      "Recall:  \t\t 0.19248826291079812\n",
      "Precision: \t\t 0.984\n",
      "F1 score: \t\t 0.32198952879581155\n",
      "AUC: \t\t\t 0.9847169033668577\n"
     ]
    }
   ],
   "source": [
    "# Calculate performance measures\n",
    "cnf_matrix = metrics.confusion_matrix(y, y_pred)\n",
    "print(\"Confusion Matrix: \\n\", cnf_matrix)\n",
    "\n",
    "print('Classification Accuracy: ',   metrics.accuracy_score(y, y_pred))\n",
    "print('Classification Error: \\t',    1 - metrics.accuracy_score(y, y_pred))\n",
    "print(\"Recall:  \\t\\t\",               metrics.recall_score(y, y_pred))\n",
    "print(\"Precision: \\t\\t\",             metrics.precision_score(y, y_pred))\n",
    "print(\"F1 score: \\t\\t\",              metrics.f1_score(y, y_pred))\n",
    "print('AUC: \\t\\t\\t',                 metrics.roc_auc_score(y, y_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Proper way to depict a confusion matrix\n",
    "metrics.plot_confusion_matrix(fullmodel,X,y,\n",
    "                              cmap='Blues',\n",
    "                              values_format='n');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into a training and test set. Note that four objects are assigned simultanesouly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# random state is similair to setting the seed\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00243902 0.00243902 0.00163934]\n",
      "Confusion Matrix: \n",
      " [[7035   24]\n",
      " [ 229    0]]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=10,max_depth=15)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "rf_matrix = metrics.confusion_matrix(y_test, rf_pred)\n",
    "rf_pred_prob = rf.predict_proba(X_test)\n",
    "print(y_pred_prob[0:3])\n",
    "rf_pred_prob = rf_pred_prob[:,1]\n",
    "print(\"Confusion Matrix: \\n\", rf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy:  0.9652854006586169\n",
      "Classification Error: \t 0.0347145993413831\n",
      "Recall:  \t\t 0.0\n",
      "Precision: \t\t 0.0\n",
      "F1 score: \t\t 0.0\n",
      "AUC: \t\t\t 0.7190476897466209\n"
     ]
    }
   ],
   "source": [
    "print('Classification Accuracy: ',   metrics.accuracy_score(y_test, rf_pred))\n",
    "print('Classification Error: \\t',    1 - metrics.accuracy_score(y_test, rf_pred))\n",
    "print(\"Recall:  \\t\\t\",               metrics.recall_score(y_test, rf_pred))\n",
    "print(\"Precision: \\t\\t\",             metrics.precision_score(y_test, rf_pred))\n",
    "print(\"F1 score: \\t\\t\",              metrics.f1_score(y_test, rf_pred))\n",
    "print('AUC: \\t\\t\\t',                 metrics.roc_auc_score(y_test, rf_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize ROC curve using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# ROC curve, needs y_pred_prob, returns three objects in this order\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, rf_pred_prob)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve for classifier')\n",
    "plt.xlabel('False positive rate (1 - specificity)')\n",
    "plt.ylabel('True positive rate (sensitivity)')\n",
    "plt.plot([0, 1], [0, 1], \"r--\") # horizontal line to represent random classifier\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Model tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7760664597730055\n",
      "{'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "# Selection of parameters with (few and randomly picked!) example values:\n",
    "# n_estimators : integer (default=10 --> The number of trees in the forest.\n",
    "# max_features : int, float, string or None (default=â€autoâ€) The number of features to consider when looking for the best split\n",
    "# criterion : string (default=â€giniâ€), or entropy\n",
    "# max_depth : integer or None (default=None) The maximum depth of the tree.\n",
    "# min_samples_split : int, float (default=2) --> The minimum number of samples required to split an internal node.\n",
    "# min_samples_leaf : int, float (default=1) --> The minimum number of samples required to be at a leaf node.\n",
    "param_grid = {'n_estimators': [10, 20, 30], \n",
    "              'max_features': ['log2', 'sqrt','auto'], \n",
    "              'criterion': ['entropy', 'gini'], # More detailed than caret\n",
    "              'max_depth': [5, 10], \n",
    "              'min_samples_split': [4],\n",
    "              'min_samples_leaf': [10]\n",
    "             }\n",
    "\n",
    "# Set up the grid object specifying the tuning options (grid search + cross validation)\n",
    "grid = GridSearchCV(rf, param_grid, cv = 3, scoring = 'roc_auc')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "myBestModel = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of best model:  0.7811323275870068\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit a model using the best hyperparameter settings using the whole training data set, and assess this model on the test set. \n",
    "myBestModel.fit(X_train, y_train)\n",
    "y_pred_best = myBestModel.predict(X_test)\n",
    "y_pred_best_prob = myBestModel.predict_proba(X_test)[:,1]\n",
    "print('AUC of best model: ', metrics.roc_auc_score(y_test, y_pred_best_prob))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This seems to be a nice tutorial on how to tune keras models using sklearn \n",
    "[https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression (reminder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running a classification task we are looking for a probability of a certain outcome. Here is the sigmoid function where *p* stands for target probability:\n",
    "$$p=\\frac{1}{1+e^{-y}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression formula would then be:\n",
    "\n",
    "$$y=ln(\\frac{p}{1-p})=\\beta_{0}+\\beta_{1}X_{1}+\\beta_{2}X_{2}+...+\\beta_{k}X_{k}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's present the formula in a slightly more general way:\n",
    "\n",
    "$$y=WX+b$$\n",
    "\n",
    "where the W is standing for the **weight** matrix, containing coefficients/betas for respective explanatory variables, and b is an error term or a **bias**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not sure it makes sense\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LogReg = LogisticRegression(solver='lbfgs', max_iter=100)\n",
    "LogReg.fit(X_train, y_train)\n",
    "y_pred = LogReg.predict(X_test)\n",
    "y_pred = LogReg.predict(X_test)\n",
    "\n",
    "#### add explanation of logit functionning, let's try to do it manually. how do you optimise and how do you choose a measure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression for multiclass task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>track_name</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>currency</th>\n",
       "      <th>price</th>\n",
       "      <th>rating_count_tot</th>\n",
       "      <th>rating_count_ver</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>user_rating_ver</th>\n",
       "      <th>ver</th>\n",
       "      <th>cont_rating</th>\n",
       "      <th>prime_genre</th>\n",
       "      <th>sup_devices.num</th>\n",
       "      <th>ipadSc_urls.num</th>\n",
       "      <th>lang.num</th>\n",
       "      <th>vpp_lic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>281656475</td>\n",
       "      <td>PAC-MAN Premium</td>\n",
       "      <td>100788224</td>\n",
       "      <td>USD</td>\n",
       "      <td>3.99</td>\n",
       "      <td>21292</td>\n",
       "      <td>26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.3.5</td>\n",
       "      <td>4+</td>\n",
       "      <td>Games</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>281796108</td>\n",
       "      <td>Evernote - stay organized</td>\n",
       "      <td>158578688</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.00</td>\n",
       "      <td>161065</td>\n",
       "      <td>26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.2.2</td>\n",
       "      <td>4+</td>\n",
       "      <td>Productivity</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>281940292</td>\n",
       "      <td>WeatherBug - Local Weather, Radar, Maps, Alerts</td>\n",
       "      <td>100524032</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.00</td>\n",
       "      <td>188583</td>\n",
       "      <td>2822</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0.0</td>\n",
       "      <td>4+</td>\n",
       "      <td>Weather</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>282614216</td>\n",
       "      <td>eBay: Best App to Buy, Sell, Save! Online Shop...</td>\n",
       "      <td>128512000</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.00</td>\n",
       "      <td>262241</td>\n",
       "      <td>649</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.10.0</td>\n",
       "      <td>12+</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>282935706</td>\n",
       "      <td>Bible</td>\n",
       "      <td>92774400</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.00</td>\n",
       "      <td>985920</td>\n",
       "      <td>5320</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.5.1</td>\n",
       "      <td>4+</td>\n",
       "      <td>Reference</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>283619399</td>\n",
       "      <td>Shanghai Mahjong</td>\n",
       "      <td>10485713</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.99</td>\n",
       "      <td>8253</td>\n",
       "      <td>5516</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4+</td>\n",
       "      <td>Games</td>\n",
       "      <td>47</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>283646709</td>\n",
       "      <td>PayPal - Send and request money safely</td>\n",
       "      <td>227795968</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.00</td>\n",
       "      <td>119487</td>\n",
       "      <td>879</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.12.0</td>\n",
       "      <td>4+</td>\n",
       "      <td>Finance</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>284035177</td>\n",
       "      <td>Pandora - Music &amp; Radio</td>\n",
       "      <td>130242560</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1126879</td>\n",
       "      <td>3594</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.4.1</td>\n",
       "      <td>12+</td>\n",
       "      <td>Music</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>284666222</td>\n",
       "      <td>PCalc - The Best Calculator</td>\n",
       "      <td>49250304</td>\n",
       "      <td>USD</td>\n",
       "      <td>9.99</td>\n",
       "      <td>1117</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6.6</td>\n",
       "      <td>4+</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>284736660</td>\n",
       "      <td>Ms. PAC-MAN</td>\n",
       "      <td>70023168</td>\n",
       "      <td>USD</td>\n",
       "      <td>3.99</td>\n",
       "      <td>7885</td>\n",
       "      <td>40</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0.4</td>\n",
       "      <td>4+</td>\n",
       "      <td>Games</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                         track_name  size_bytes  \\\n",
       "0  281656475                                    PAC-MAN Premium   100788224   \n",
       "1  281796108                          Evernote - stay organized   158578688   \n",
       "2  281940292    WeatherBug - Local Weather, Radar, Maps, Alerts   100524032   \n",
       "3  282614216  eBay: Best App to Buy, Sell, Save! Online Shop...   128512000   \n",
       "4  282935706                                              Bible    92774400   \n",
       "5  283619399                                   Shanghai Mahjong    10485713   \n",
       "6  283646709             PayPal - Send and request money safely   227795968   \n",
       "7  284035177                            Pandora - Music & Radio   130242560   \n",
       "8  284666222                        PCalc - The Best Calculator    49250304   \n",
       "9  284736660                                        Ms. PAC-MAN    70023168   \n",
       "\n",
       "  currency  price  rating_count_tot  rating_count_ver  user_rating  \\\n",
       "0      USD   3.99             21292                26          4.0   \n",
       "1      USD   0.00            161065                26          4.0   \n",
       "2      USD   0.00            188583              2822          3.5   \n",
       "3      USD   0.00            262241               649          4.0   \n",
       "4      USD   0.00            985920              5320          4.5   \n",
       "5      USD   0.99              8253              5516          4.0   \n",
       "6      USD   0.00            119487               879          4.0   \n",
       "7      USD   0.00           1126879              3594          4.0   \n",
       "8      USD   9.99              1117                 4          4.5   \n",
       "9      USD   3.99              7885                40          4.0   \n",
       "\n",
       "   user_rating_ver     ver cont_rating   prime_genre  sup_devices.num  \\\n",
       "0              4.5   6.3.5          4+         Games               38   \n",
       "1              3.5   8.2.2          4+  Productivity               37   \n",
       "2              4.5   5.0.0          4+       Weather               37   \n",
       "3              4.5  5.10.0         12+      Shopping               37   \n",
       "4              5.0   7.5.1          4+     Reference               37   \n",
       "5              4.0     1.8          4+         Games               47   \n",
       "6              4.5  6.12.0          4+       Finance               37   \n",
       "7              4.5   8.4.1         12+         Music               37   \n",
       "8              5.0   3.6.6          4+     Utilities               37   \n",
       "9              4.0   4.0.4          4+         Games               38   \n",
       "\n",
       "   ipadSc_urls.num  lang.num  vpp_lic  \n",
       "0                5        10        1  \n",
       "1                5        23        1  \n",
       "2                5         3        1  \n",
       "3                5         9        1  \n",
       "4                5        45        1  \n",
       "5                5         1        1  \n",
       "6                0        19        1  \n",
       "7                4         1        1  \n",
       "8                5         1        1  \n",
       "9                0        10        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "app = pd.read_csv(\"AppleStore.csv\")\n",
    "app=app.drop(['Unnamed: 0'],axis=1)\n",
    "app.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app[\"user_rating\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a multiclass problem, we want to figure out which user rating will the app receive, options are [0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5] - there are __11__ possible labels\n",
    "\n",
    "We have the $$y=WX+b$$\n",
    "The resulting *y* is a logit or a score:\n",
    "\n",
    "$$\\hat{y}=score(X_{i},k)=\\beta_{k}X_{i}$$\n",
    "\n",
    "where *i* is the number of observation and *k* is the rank level (\"1\", \"4.5\", etc.)\n",
    "\n",
    "The scores then would have to be transformed to the probability. You have been exposed to different ways of converting the probability to the actual binary outcome, however, here we have a multiclass problem, so we will need another tool - softmax.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax function:\n",
    "\n",
    "$$S(y_{i})=\\frac{e^{y_{i}}}{\\sum_{j} e^{y_{i}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(=) When we develop a model for probabilistic classification, we aim to map the model's inputs to probabilistic predictions, and we often train our model by incrementally adjusting the model's parameters so that our predictions get closer and closer to ground-truth probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [-100, -10, -0.5, -0.1, 0, 0.21, 1, 1.8, 5, 100]\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "print(softmax(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our observation can only be labelled as one class, so the probabilities should sum up to 1, check it\n",
    "sum(softmax(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we are trying to classify the input as \"5\", \"1,5\"... rank labels and we feed an information about the **3.5** app, then we would like to see our probabilities looking more like [0.08 0.1 0.02 0.1 0.06 0.08 0.001 0.81 0.004 0.03 0.0002 ], it would mean that the model is getting a grasp of the data. \n",
    "\n",
    "[0.2135499  0.17483987 0.07935017 0.38911329 0.14314678 0.2135499  0.17483987 0.07935017 0.38911329 0.14314678 0.1231] means that our model is somewhat on the way but still a little uncertain, we need to give her a nudge in the right direction. So how do you usually tell the model it's wrong? You show it the evaluation metric and try to make it better.\n",
    "\n",
    "To evaluate the the probabilities estimated by the model we need to compare them with the true values, \n",
    "that are one-hot encoded in our case. So we need to compare\n",
    "\n",
    "[0.2135499  0.17483987 0.07935017 0.38911329 0.14314678 0.2135499  0.17483987 0.07935017 0.38911329 0.14314678 0.1231]\n",
    "and [0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0]. You can imagine that we can not use MSE here, as we are dealing with a certain probability distribution. Our loss function has to grasp the difference between these probabilities, here is where the cross-entropy will come in handy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss functions\n",
    "### Logistic regression case\n",
    "$$J(w) = \\sum_{i=1}^{m} y^{(i)} \\log P(y=1) + (1 - y^{(i)}) \\log P(y=0)$$\n",
    "Where P(y) represent the probability of a certain binary outcome\n",
    "\n",
    "We will however consider another loss functin - cross entropy. It is used when output represents the probability of an outcome, i.e. when the output is a probability distribution. It is used as a loss function in neural networks which have softmax activations in the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-entropy \n",
    "Entropy (H(y)) is a term from Information Theory. It had a great impact on the field of communication and signifies the optimal number of bits to encode a certain information content ($y_i$ is the probability of the i-th event, symbol or in our case class):\n",
    "\n",
    "$$H(y) = \\sum_i y_i \\log \\frac{1}{y_i} = -\\sum_i y_i \\log y_i$$\n",
    "\n",
    "Now the cross-entropy (H(y,y^)) is the number of bits we'll need if we encode symbols from  y using the wrong tool y^. Cross entropy is always bigger or equal to entropy. Mind that i stands for the number of classes. \n",
    "\n",
    "$$H(y, \\hat{y}) = \\sum_i y_i \\log \\frac{1}{\\hat{y}_i} = -\\sum_i y_i \\log \\hat{y}_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly enough, the The KL divergence that you have encountered before in BADS (uplift random forest) is simply the difference between cross entropy and entropy:\n",
    "$$\\mbox{KL}(y~||~\\hat{y})\n",
    "= \\sum_i y_i \\log \\frac{1}{\\hat{y}_i} - \\sum_i y_i \\log \\frac{1}{y_i}\n",
    "= \\sum_i y_i \\log \\frac{y_i}{\\hat{y}_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would be calculating the cross-entropy for every vector of true/estimated probabilities and averaging it over the sample or batch (more about it later) - this will be our loss function *L* that we will ultimately want to minimise (class i, smaple j):\n",
    "\n",
    "$$L=-\\frac{1}{N}\\sum_j \\sum_i y_i \\log(WX_i+b)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CE example\n",
    "#A concrete example is the best way to explain the purely mathematical form of CE. Suppose you have a weirdly shaped four-sided dice (yes, I know the singular is really \"die\").\n",
    "#Using some sort of intuition or physics, you predict that the probabilities of the four sides are (0.20, 0.40, 0.30, 0.10). \n",
    "# Then you roll the dice many thousands of times and determine that the true probabilities are (0.15, 0.35, 0.25, 0.25). \n",
    "# The CE error for your prediction is:\n",
    "-1.0 * [ ln(0.20) * 0.15 + ln(0.40) * 0.35 + ln(0.30) * 0.25 + ln(0.10) * 0.25 ] =\n",
    "-1.0 * [ (-1.61)(0.15) + (-0.92)(0.35) + (-1.20)(0.25) + (-2.30)(0.25) ] =\n",
    "1.44\n",
    "#https://visualstudiomagazine.com/articles/2017/07/01/cross-entropy.aspx\n",
    "\n",
    "#picture below will be redone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"lossf.png\" alt=\"lossstruct\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In our naive example N=1, as we are only dealing with 1 batch (j=1), while we have 5 classes (i=5) \n",
    "true =   [0 ,0    ,    0,0 ,    0, 0,   0, 1, 0, 0,  0]\n",
    "scores = [-1, -0.5, -0.1, 0, 0.21, 1, 1.8, 4, 0, 1,0.1]\n",
    "yhat=softmax(scores)#that's our WX+b\n",
    "\n",
    "L=-sum(true*np.log(yhat))\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to minimise the loss, we would need a derivative.\n",
    "NB: Our i an j would potentially go into thousands, calculating the derivative of the loss function will become extremely hard. And that was the point when everybody almost gave up on neural networks. We will learn about the solution  - backpropagation and stochastic gradient descent at the next tutorial. \n",
    "\n",
    "NB: Keep in mind, that depending on the task, just like in previous machine learning cases, you can choose a specific loss function that fits your goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient (reminder)\n",
    "The gradient is a vector operation which operates on a scalar function to produce a vector whose magnitude is the maximum rate of change of the function at the point of the gradient and which is pointed in the direction of that maximum rate of change. \n",
    " $$\\nabla L$$\n",
    " \n",
    " <img src=\"gradient_descent.png\" alt=\"lossstruct\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "We want to adjust every estimation of y so as to minimize the loss function. For that we would deduct a gradient of the loss function from it and continue doing these iterations until we reach the local minimum. \n",
    "$$L_{t+1} =L_t - \\eta . \\nabla L(W_{ij})$$\n",
    "$\\eta$ stands here for a *learning rate* - a very important concept to keep in mind.\n",
    "As we will learn later, we will need a chain rule in order to calculate the gradient for the neural network case. At the moment we can see how the gradient descent works on a simple function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will try to find the local minimum of (x-4)^2 function. In this case gradient is a simple derivative\n",
    "\n",
    "cur_x = 10 \n",
    "rate = 0.1 # Learning rate\n",
    "precision = 0.000001 #This tells us when to stop the algorithm\n",
    "previous_step_size = 1 #\n",
    "max_iters = 20 # maximum number of iterations\n",
    "iters = 0 #iteration counter\n",
    "df = lambda x: 2*(x-4) #Gradient of our function '\n",
    "\n",
    "while previous_step_size > precision and iters < max_iters:\n",
    "    prev_x = cur_x #Store current x value in prev_x\n",
    "    cur_x = cur_x - rate * df(prev_x) #Grad descent\n",
    "    previous_step_size = abs(cur_x - prev_x) #Change in x\n",
    "    iters = iters+1 #iteration count\n",
    "    print(\"Iteration\",iters,\"\\nX value is\",cur_x) #Print iterations\n",
    "    \n",
    "print(\"The local minimum occurs at\", cur_x)\n",
    "\n",
    "#https://towardsdatascience.com/implement-gradient-descent-in-python-9b93ed7108d1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep this theory in mind - we will map all those concepts on the neural network design to make better sense of them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (adams)",
   "language": "python",
   "name": "pycharm-feb95198"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
